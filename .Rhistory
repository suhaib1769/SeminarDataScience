sigma ~ dunif(0.001, 10)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
install.packages("CmdStanR")
install_cmdstan()
set_cmdstan_path()
da <- sample
m <-ulam(
alist(
age ~ dnorm(mu, sigma),
mu ~ dnorm(42.4, 5),
sigma ~ dunif(0.001, 10)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
precis(m,prob=0.95)
traceplot(m)
traceplot(m)
t.test(sample$age, mu=60, conf.level = 0.9)
library(rethinking)
da <- sample
m <-ulam(
alist(
age ~ dnorm(mu, sigma),
mu ~ dnorm(42.4, 20),
sigma ~ dunif(0.001, 10)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
precis(m,prob=0.95)
traceplot(m)
sample2 <- data.frame(usability = rnorm(34,7.2))
library(rethinking)
da <- sample2
m <-ulam(
alist(
usability ~ dnorm(mu, sigma2),
mu ~ dnorm(5, 5),
sigma ~ dunif(0.1, 5)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
sample2 <- data.frame(usability = rnorm(34,7.2))
library(rethinking)
da <- sample2
m <-ulam(
alist(
usability ~ dnorm(mu, sigma),
mu ~ dnorm(5, 5),
sigma ~ dunif(0.1, 5)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
precis(m,prob=0.95)
sample2 <- data.frame(usability = rnorm(34,7.2))
library(rethinking)
da <- sample2
m0 <-ulam(
alist(
usability ~ dnorm(mu, sigma),
mu ~ dnorm(5, 5),
sigma ~ dunif(0.1, 5)
), data = da ,iter = 10000, chains = 4, cores = 4,
)
precis(m,prob=0.95)
knitr::opts_chunk$set(echo = TRUE)
#include your code for generating the synthetic data
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
setwd("~/surfdrive/Teaching/own teaching/IN4125 - Seminar Research Methodology for Data Science/2019/coursework A")
---
title: "Coursework assignment A - 2022-2023"
knitr::opts_chunk$set(echo = TRUE)
#include your code for generating the synthetic data
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
setwd("~/surfdrive/Teaching/own teaching/IN4125 - Seminar Research Methodology for Data Science/2019/coursework A")
knitr::opts_chunk$set(echo = TRUE)
#include your code for generating the synthetic data
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
setwd("/Users/suhaibbasir/Documents/CS/MSc/SRDS")
# apple , note use / instead of \, which used by windows
#install.packages("twitteR", dependencies = TRUE)
library(twitteR)
#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
library(NLP)
#install.packages("tm", dependencies = T)
library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)
library(wordcloud)
#install.packages("reshape", dependencies=T)
library(reshape)
################### functions
clearTweets <- function(tweets, excl) {
tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets
tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
tweets.text = gsub('\\d+', '', tweets.text)
tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
corpus <- Corpus(VectorSource(tweets.text))
corpus_clean <- tm_map(corpus, removePunctuation)
corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
return(corpus_clean)
}
## capture all the output to a file.
################# Collect from Twitter
# for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers
#consumer_key <-'your key'
#consumer_scret <- 'your secret'
#access_token <- 'your access token'
#access_scret <- 'your access scret'
source("wpb_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R
knitr::opts_chunk$set(echo = TRUE)
#include your code for generating the synthetic data
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
setwd("/Users/suhaibbasir/Documents/CS/MSc/SRDS")
# apple , note use / instead of \, which used by windows
#install.packages("twitteR", dependencies = TRUE)
library(twitteR)
#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
library(NLP)
#install.packages("tm", dependencies = T)
library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)
library(wordcloud)
#install.packages("reshape", dependencies=T)
library(reshape)
################### functions
clearTweets <- function(tweets, excl) {
tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets
tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
tweets.text = gsub('\\d+', '', tweets.text)
tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
corpus <- Corpus(VectorSource(tweets.text))
corpus_clean <- tm_map(corpus, removePunctuation)
corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
return(corpus_clean)
}
## capture all the output to a file.
################# Collect from Twitter
# for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers
#consumer_key <-'your key'
#consumer_scret <- 'your secret'
#access_token <- 'your access token'
#access_scret <- 'your access scret'
source("wpb_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R
knitr::opts_chunk$set(echo = TRUE)
#include your code for generating the synthetic data
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
setwd("/Users/suhaibbasir/Documents/CS/MSc/SRDS")
# apple , note use / instead of \, which used by windows
#install.packages("twitteR", dependencies = TRUE)
library(twitteR)
#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
library(NLP)
#install.packages("tm", dependencies = T)
library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)
library(wordcloud)
#install.packages("reshape", dependencies=T)
library(reshape)
################### functions
clearTweets <- function(tweets, excl) {
tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets
tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
tweets.text = gsub('\\d+', '', tweets.text)
tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
corpus <- Corpus(VectorSource(tweets.text))
corpus_clean <- tm_map(corpus, removePunctuation)
corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
return(corpus_clean)
}
## capture all the output to a file.
################# Collect from Twitter
# for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers
#consumer_key <-'your key'
#consumer_scret <- 'your secret'
#access_token <- 'your access token'
#access_scret <- 'your access scret'
source("wpb_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R
setup_twitter_oauth(consumer_key,consumer_scret, access_token,access_scret) #connect to  twitter app
data(mtcars)
mtcars$am
mtcars$am <- factor(mtcars$am, levels=c(0:1), labels=c("automatic", "manual"))
install.packages("devtools")
devtools::install_github("rasmusab/bayesian_first_aid")
# model verification with bayes.t.test
bayes.t.test(mpg ~ am, data=d, mu=0, paired=FALSE, alternative="two.sided", conf.level=0.95)
devtools::install_github("rasmusab/bayesian_first_aid")
install.packages("rjags")
devtools::install_github("rasmusab/bayesian_first_aid")
# model verification with lm
m1 <- lm(mpg ~ am, data=d)
am <- rbinom(32, 1, 0.5)
mpg <- rnorm(32, mean=30+am*5, sd=5)
am <- factor(am, levels=c(0:1), labels=c("automatic", "manual"))
d <- data.frame(mpg, am)
d
# model verification with lm
m1 <- lm(mpg ~ am, data=d)
m0 <- lm(mpg ~ 1, data=d)
(anova(m0, m1))
install.packages("rjags")
install.packages("rjags")
ls
install.packages("rjags")
install.packages("rjags", configure.args = "--with-jags-include=/opt/homebrew/opt/jags/include/JAGS --with-jags-lib=/opt/homebrew/opt/jags/lib")
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
no
install.packages("rjags")
install.packages("rjags",dependencies = TRUE, repos="http://cran.utstat.utoronto.ca/")
library(rjags)
install.packages("coda")
library(rjags)
?dnorm
# model verification with map2stan
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ dnorm(100, 25),
sigma ~ dunif(0.001, 40)
), data=d,iter = 10000, chains = 4, cores = 4
)
precise(mo_stan)
precis(m0_stan)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(0, 10),
b ~ dnorm(0, 10),
sigma ~ dunif(0, 10)
), data=d
)
precis(m1_stan)
compare(m0_stan,m1_stan, func=PSIS)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dunif(0.001, 40)
), data=d,iter = 10000, chains = 4, cores = 4
)
precis(m1_stan)
# model verification with map2stan
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ dnorm(100, 25),
sigma ~ dcauchy()(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy()(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m1_stan)
compare(m0_stan,m1_stan, func=PSIS)
compare(m0_stan,m1_stan)
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m1_stan)
compare(m0_stan, m1_stan)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
library(loo)
compare(m0_stan, m1_stan)
loo_compare(m0_stan, m1_stan)
library(BayesianFirstAid)
library(BayesianFirstAid)
precis(m0_stan)
precis(m1_stan)
loo_compare(m0_stan, m1_stan)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
# model verification with map2stan
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
compare(m0_stan, m1_stan, func=WAIC)
compare(m0_stan, m1_stan, func=WAIC)
detach("package:loo", unload = TRUE)
compare(m0_stan, m1_stan, func=WAIC)
?compare
?compare
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan, func=WAIC)
compare(m0_stan, m1_stan)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ a
a ~ dnorm(100, 25),
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu ~ a,
a ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a,
a ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
am <- rbinom(32, 1, 0.5)
mpg <- rnorm(32, mean=30+am*5, sd=5)
am <- factor(am, levels=c(0:1), labels=c("automatic", "manual"))
d <- data.frame(mpg, am)
d
# model verification with lm
m1 <- lm(mpg ~ am, data=d)
m0 <- lm(mpg ~ 1, data=d)
(anova(m0, m1))
# model verification with map2stan
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a,
a ~ dnorm(100, 25),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(100, 25),
b ~ dnorm(10, 10),
sigma ~ dcauchy(0.001, 40)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan)
compare(m0_stan, m1_stan, func=WAIC)
library(rethinking)
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a,
a ~ dnorm(25, 10),
sigma ~ dcauchy(0, 2)
), data=d, iter = 10000, chains = 4, cores = 4
)
m1_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a + b*am,
a ~ dnorm(25, 10),
b ~ dnorm(0, 5),
sigma ~ dcauchy(0, 2)
), data=d, iter = 10000, chains = 4, cores = 4
)
precis(m0_stan)
precis(m1_stan)
compare(m0_stan, m1_stan, func=WAIC)
compare(m0_stan, m1_stan)
compare(m0_stan, m1_stan)
am <- rbinom(32, 1, 0.5)
mpg <- rnorm(32, mean=30+am*5, sd=5)
am <- factor(am, levels=c(0:1), labels=c("automatic", "manual"))
d <- data.frame(mpg, am)
d
m0_stan <- map2stan(
alist(
mpg ~ dnorm(mu, sigma),
mu <- a,
a ~ dnorm(25, 10),
sigma ~ dcauchy(0, 2)
), data=d, iter = 10000, chains = 4, cores = 4
)
compare(list(m0_stan = m0_stan, m1_stan = m1_stan), labels = c("Model 0", "Model 1"))
