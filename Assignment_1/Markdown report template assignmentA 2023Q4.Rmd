---
title: "Coursework assignment A - 2022-2023"
subtitle: "CS4125 Seminar Research Methodology for Data Science"
author: "Student names"
date: "16/04/2023"
output:
   pdf_document:
      fig_caption: true
      number_sections: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\tableofcontents

# Part 1 - Design and set-up of true experiment 

## The motivation for the planned research 
(Max 200 words)
Previous research [1] has shown that while some technologies can improve student achievement, others may actually decrease it. The impact of technology is very dependent on the technology itself but also on who is using it, teachers or students. Given that ChatGPT is a widely-used innovation among students, it is important to investigate its effect on student achievement. By comparing the learning outcomes, intrinsic motivation, and perceived difficulty of students who have access to ChatGPT with those who rely on traditional coding resources, the research aims to determine if ChatGPT can improve student achievement in a challenging coding assignment.

1. New global data reveal education technologyâ€™s impact on learning. (2020, June 12). McKinsey & Company. https://www.mckinsey.com/industries/education/our-insights/new-global-data-reveal-education-technologys-impact-on-learning#/
2.Lancaster, Thomas & wilkinson, richard. (2014). Improving Student Motivation Using Technology Within The STEM Disciplines. 

## The theory underlying the research  
(Max 200 words) Preferable based on theories reported in literature
The main theory which encompasses this topic is within the field of educational technologies. According to a paper by Francis et al. discusses the effects of technology on student motivation and engagement in classroom-based learning. The study found that students feel motivated through the specific use of technology in the classroom, whether it be for educational purposes or for accommodation in the classroom. This suggests that as technology continues to advance, there is potential for even greater impact on student motivation and engagement in the classroom. The integration of technology into education can help teachers differentiate instruction, motivate students, and include all skill levels. However, some studies also indicate that the extensive use of internet resources can reduce the difficulty level of college assignments and thus reduce student motivation, as outlined in a study conducted at Swansea university. Furthermore, the study conducted at Swansea University highlighted that excessive reliance on internet resources for assignments can potentially undermine students' motivation by diminishing the perceived challenge and authenticity of the tasks. Therefore, it is important to strike a balance in usingutilizing technology in the classroom to maintain an optimal level of student engagement and motivation while ensuring the integrity and rigor of assignments. Ongoing research in educational technologies continues to explore the nuances of these effects and aims to provide evidence-based guidelines for effective integration of technology in education.

## Research questions 
What are the differences in learning outcomes, intrinsic motivation, and perceived difficulty between students who have access to a conversational AI tool (e.g., Chat-GPT) and those who rely on traditional coding resources while completing a challenging coding assignment?

## The related conceptual model 
Independent variable(s): Use of chatgpt for an assignment
Dependent variable: Grade received for the assignment
Mediating variable (at least 1): Motivation, Interest
Moderating variable (at least 1): Experience level: Number of years in university (the student a 1st year bachelor or a final year masters student, or somewhere in between)

## Experimental Design 
Experimental Design (the study should have a true experimental design to test a single hypothesis that, for simplicity, includes only independent variable(s) and dependent variable(s). In other words, mediating and moderating variables are not included in the experimental design ) 
Our hypothesis is that the use of ChatGPT affects the grade received for an assignment. We will focus on the relationship between the independent variable (use of ChatGPT) and the dependent variable (grade received for the assignment). Students / participants will be divided into two groups: one group that is allowed to use ChatGPT (treatment group) and one that is not allowed to use ChatGPT (control group). Therefore this is a between subjects experiment.

## Experimental procedure 
Describe how the experiment will be executed step by step
Students will be given the same assignment at the same time. They also have the same assignment deadline. During the assignment, one group is told that they can use the internet as they like but cannot communicate with other students about the assignment. The other group is told the same but also that they are not allowed to use ChatGPT or any AI to make the assignment. The assignments will then be graded without the knowledge on whether ChatGPT is used or not. The grades will be compared using a statistical tests such as t-test. 

## Measures
Describe the measure that will be used
The primary measure in this study is the grade received for the assignment. This will be the dependent variable of interest, indicating participants' performance on the assignment. Additionally, a pretest measure of participants' baseline academic performance (GPA) will be collected to control for initial differences.
We will also be measuring their motivation during the process of the study using a tool such as the Intrinsic Motivation Inventory. The Intrinsic Motivation Inventory (IMI) is a self-report questionnaire that measures an individual's intrinsic motivation. It assesses factors such as enjoyment, competence, effort, and relatedness in a specific context or activity. By using the IMI, researchers can gain insights into individuals' internal motivation levels, which helps understand their engagement and interest in a particular task or domain. The inventory provides a quantitative measurement of intrinsic motivation, allowing for comparisons across individuals or groups and guiding the development of interventions or strategies to enhance motivation.

## Participants
Describe which participants will recruit in the study and how they will be recruited
We will recruit participants from students studying computer science at TU Delft, including both Bachelor's and Master's students. The recruitment will take place by approaching students before lectures of computer science courses within the program.

## Suggested statistical analyses
Describe the statistical test you suggest to care out on the collected data
A t-test would be appropriate for the data analysis. It compares the mean grades between the two groups (ChatGPT usage vs. no ChatGPT usage) while considering within-group variability. By conducting a t-test, we can determine if the observed mean grade difference is statistically significant, indicating the impact of ChatGPT on assignment performance. 
Alternatively, a permutation test can be used as a non-parametric approach. It assesses the significance of the mean difference by randomly shuffling group labels and calculating mean differences multiple times. This test is useful when sample sizes are small or data does not follow a normal distribution.

# Part 2 - Generalized linear models

## Question 1 Twitter sentiment analysis (Between groups - single factor) 

##### Loaded tweets of Hillary Clinton, Donald Trump and Bernie Sanders from the .txt files provided in the assignment.
```{r , warning=FALSE, message=FALSE, results='hide'}
# setwd("/Users/suhaibbasir/Documents/CS/MSc/SRDS/SeminarDataScience/Assignment_1")
getwd()
tweets_B <- read.table("tweets_B.txt", sep = "\n", header = T)
tweets_B <- tweets_B[seq(1, nrow(tweets_B), 2), ]

tweets_C <- read.table("tweets_C.txt", sep = "\n", header = T)
tweets_C <- tweets_C[seq(1, nrow(tweets_C), 2), ]

tweets_T <- read.table("tweets_T.txt", sep = "\n", header = T)
tweets_T <- tweets_T[seq(1, nrow(tweets_T), 2), ]

# taken from https://github.com/mjhea0/twitter-sentiment-analysis
pos <- scan("positive-words.txt", what = "character", comment.char = ";") # read the positive words
neg <- scan("negative-words.txt", what = "character", comment.char = ";") # read the negative words

source("sentiment3.R") # load algorithm
# see sentiment3.R form more information about sentiment analysis. It assigns a intereger score
# by subtracting the number of occurrence of negative words from that of positive words

analysis_T <- score.sentiment(tweets_T, pos, neg)
analysis_C <- score.sentiment(tweets_C, pos, neg)
analysis_B <- score.sentiment(tweets_B, pos, neg)

```
```{r , warning=FALSE, message=FALSE}
sem <- data.frame(analysis_T$score, analysis_C$score, analysis_B$score)

library(reshape2)
semFrame <- melt(sem, measured = c(analysis_T.score, analysis_C.score, analysis_B.score))
names(semFrame) <- c("Candidate", "score")
semFrame$Candidate <- factor(semFrame$Candidate, labels = c("Donald Trump", "Hillary Clinton", "Bernie Sanders")) # change the labels for your individual/organisation
head(semFrame)
# The data you need for the analyses can be found in semFrame
```

### Conceptual model
Make a conceptual model for the following research question: Is there a difference in the sentiment of the tweets related to the different individuals/organisations? 

Based on the research questions our conceptual model consists of the following variables:
- Independent variable: The different individuals/organisations (Hillary Clinton, Donald Trump, Bernie Sanders)
- Dependent variable: Sentiment of the tweets (positive, negative, neutral)
This is visualised in the diagram below:
```{r}
knitr::include_graphics("conceptualModel.png")
```

### Model description
Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Assume a Gaussian distribution for the tweetâ€™s sentiments rating. Justify the priors.

The mathematical model fitted on the most extensive model is a linear model. The model is formulated as follows:

$$
y_i = \beta_0 + \beta_1 x_i + \epsilon_i 
$$

Where $y_i$ is the sentiment of the tweet, $\beta_0$ is the intercept, $\beta_1$ is the slope, $x_i$ is the individual/organisation and $\epsilon_i$ is the error term.

### Generate Synthetic data
Create a synthetic data set with a clear difference between tweetsâ€™ sentiments of celebrities for verifying your analysis later on. Report the values of the coefficients of the linear model used to generate synthetic data. (hint, look at class lecture slides of lecture on Generalized linear models for example to create synthetic data)
Coefficients: we pick values between -3 and 5 since we found those values in the original dataset, and pick 300 numbers. If a value is picked we replace this value so it can be picked again.
```{r}
# #include your code for generating the synthetic data and output in the document

set.seed(123) # for reproducibility

# Set the baseline sentiment (Î²_0), and the sentiment effect for each individual (Î²_1)
beta_0 <- 0
beta_1 <- c("Donald Trump" = 1.1, "Hillary Clinton" = 0, "Bernie Sanders" = 0.2)

# Create a vector of individuals, repeated 100 times each
individuals <- rep(c("Donald Trump", "Hillary Clinton", "Bernie Sanders"), each = 100)

# Calculate the sentiment for each individual
sentiment <- beta_0 + beta_1[individuals] + rnorm(length(individuals), mean = 0, sd = 1)

# Create a data frame with the results
synthetic <- data.frame(
  individual = individuals,
  sentiment = sentiment
)
```
### Visual inspection Mean and distribution sentiments
Graphically examine the mean and distribution sentiments of tweets for each individual/organisation, and provide interpretation

```{r}
library(ggplot2)
mean_data <- aggregate(score ~ Candidate, data = semFrame, FUN = mean)

ggplot() +
  geom_boxplot(data = semFrame, aes(x = Candidate, y = score)) +
  geom_jitter(data = semFrame, aes(x = Candidate, y = score), width = 0.2, height = 0, alpha = 0.5) +
  geom_point(
    data = mean_data, aes(x = Candidate, y = score, fill = "Mean"),
    shape = 23, size = 3
  ) +
  labs(x = "Individual", y = "Sentiment", title = "Distribution of sentiment for each individual") +
  scale_fill_manual(name = "Legend", values = "red", guide = guide_legend(override.aes = list(shape = 23)))
```

The median of the sentitment is 0 for all candidates and while the mean for Clinton and Sanders are close, the mean for Trump is higher than both. Trump is also the only one with sentiment scores above 3 with quite a few scores of 5. Overall, Trump has more positive tweets and only the 'Clinton' group exhibits a negative 25% mark. This means that the lower quartile of sentiment scores for Clinton are located below zero, indicating a relatively more negative sentiment compared to the other groups. She is however the only one without a score lower than -2.

### Frequentist approach

#### Analysis verification
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of AICc, F-value, p-value etc.

```{r}
# include your analysis code of synthetic data and output in the document
m0 <- lm(sentiment ~ 1, data = synthetic)
m1 <- lm(sentiment ~ individual, data = synthetic)
summary(m1)
anova(m0, m1)
AIC(m0, m1)
```

In the synthetic data generation, the sentiment means for "Donald Trump", "Hillary Clinton", and "Bernie Sanders" were set as 1.1, 0, and 0.1, respectively; these priors are based on the visual we made using the real data. 
Upon running a linear model on the synthetic data, the estimated coefficients very closely represented the means and differences used in the data generation process. 
The intercept, representing Bernie Sanders' sentiment mean, was estimated around 0.3 
The coefficients for "Donald Trump" and "Hillary Clinton" represented the differences in sentiment from Bernie Sanders, which were closely estimated around 0.8 and -0.4, respectively. 
These small discrepancies arise from the random noise added during data generation. Thus, the model has almost effectively reproduced the coefficients from the data generation process.

The model m1, with a lower AIC value of 821.45 compared to m0's 903.211, indicates a better fit to the data while considering model complexity. 
The F-statistic and the associated p-value would shed light on the overall significance of the model - if the p-value is less than the conventional 0.05 threshold, it indicates the predictors in the model significantly improve its fit compared to an intercept-only model. 

#### Linear model
Redo the analysis now on the real tweet data set. Provide a short interpretation of the results, with an interpretation of AICc, F-value, p-value, etc.

```{r}
# include your analysis code and output in the document
m0_real <- lm(score ~ 1, data = semFrame)
m1_real <- lm(score ~ Candidate, data = semFrame)
summary(m1_real)
anova(m0_real, m1_real)
AIC(m0_real, m1_real)
```

For the real data, the same holds as for the synthetic data. The P-value is even smaller and F-value is even bigger. Meaning that the difference is bigger than with the synthetic data.

#### Post Hoc analysis
If a model that includes the individual better explains the sentiments of tweets than a model without such predictor, conduct a posthoc analysis with, e.g., Bonferroni correction to examine which celebrity tweets differ from the other individualâ€™s tweets. Provide a brief interpretation of the results.

```{r}
pairwise.t.test(semFrame$score, semFrame$Candidate, p.adjust.method = "bonferroni")
```

The difference in sentiment of the tweets is significant with Bonferroni correction with a P-value of 1.4e-6 between Trump and Clinton and 3.6e-5 between Trump and Sanders. There is no significant difference in the sentiment of the tweets between Clinton and Sanders.

#### Report section for a scientific publication
Write a small section for a scientific publication (journal or a conference), in which you report the results of the analyses, and explain the conclusions that can be drawn in a format commonly used by the scientific community Look at Brightspace for examples papers and guidelines on how to do this. (Hint, there are strict guidelines for reporting statistical results in paper, I expect you to follow these here) 

The analysis of variance (ANOVA) was performed to compare the fit of two models: Model 1 and Model 2. Model 1 represents the null model, while Model 2 includes the additional predictor variable.

The results of the ANOVA revealed a significant difference between the models, indicating that the inclusion of the predictor variable, the candidate that the tweet was about, significantly improved the fit of the model, F(2, 297) = 14.155, p < 0.05.

Furthermore, the AIC values provide additional evidence supporting the superiority of Model 2. Model 1 had an AIC value of 1432.224, while Model 2 had a lower AIC value of 1421.824. The lower AIC value for Model 2 indicates a better balance between model fit and complexity, suggesting that Model 2 provides a more parsimonious representation of the data.

The F-value of 14.155 indicates the ratio of the variance explained by the Candidate variable compared to the residual variance. The obtained F-value exceeds the critical value at the chosen level of significance (p < 0.05), further affirming the statistical significance of the improvement in model fit with the inclusion of the Candidate variable.
These findings collectively support the hypothesis that the Candidate variable is a significant factor in explaining the variation in the scores. The results suggest that Model 2, which includes the Candidate variable, provides a more accurate representation of the relationship between the Candidate and the scores compared to Model 1.

We also conducted a post hoc analysis to examine pairwise comparisons between the scores of different candidates using the Bonferroni adjustment method. The analysis was performed using a pairwise t-test.
The pairwise comparisons revealed significant differences in scores between certain candidates. Specifically, the scores of Hillary Clinton and Donald Trump were significantly different (p < 0.01), with Donald Trump exhibiting higher scores compared to Hillary Clinton. Additionally, the scores of Bernie Sanders and Hillary Clinton were also significantly different (p = 0.00011), with Bernie Sanders having higher scores compared to Hillary Clinton.
These findings suggest that there are significant variations in the sentiment expressed towards different candidates. Specifically, Donald Trump received higher sentiment scores compared to Hillary Clinton, while Bernie Sanders received higher sentiment scores compared to Hillary Clinton.
The Bonferroni adjustment method was employed to address multiple comparisons, ensuring a stricter control of the overall type I error rate. This adjustment method accounts for the increased risk of false positives when conducting multiple comparisons.
Overall, the post hoc analysis provides further insights into the sentiment differences between candidates and supports the notion that the sentiment expressed towards different candidates varies significantly.


### Bayesian Approach
For the Bayesian analyses, use the rethinking and/or BayesianFirstAid library

#### Analysis verification
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of WAIC, and 95% credibility interval of coefficients for individual celebrities.

```{r , warning=FALSE, message=FALSE, results='hide'}
# include your analysis code of synthetic data and output in the document
synthetic$individual <- as.factor(synthetic$individual)
library(rethinking)
m0_bayes <- map2stan(
  alist(
    sentiment ~ dnorm(mu, sigma),
    mu <- a,
    a ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = synthetic, iter = 10000, chains = 4, cores = 4
)
m1_bayes <- map2stan(
  alist(
    sentiment ~ dnorm(mu, sigma),
    mu <- a + b[individual],
    a ~ dnorm(0, 10),
    b[individual] ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = synthetic, iter = 10000, chains = 4, cores = 4
)
```
  
```{r}
precis(m0_bayes)
precis(m1_bayes)
compare(m0_bayes, m1_bayes)
```

#### Model comparison
Redo the analysis on the actual tweet data set. Provide a short interpretation of the results, with a reflection of WAIC, and 95% credibility interval of coefficients for individual celebrities.

```{r , warning=FALSE, message=FALSE, results='hide'}
# include your analysis code and output in the document
semFrame$Candidates <- as.factor(semFrame$Candidate)
# revert to the original data frame
library(rethinking)
m0_bayes_real <- map2stan(
  alist(
    sentiment ~ dnorm(mu, sigma),
    mu <- a,
    a ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = semFrame, iter = 10000, chains = 4, cores = 4
)
m1_bayes_real <- map2stan(
  alist(
    sentiment ~ dnorm(mu, sigma),
    mu <- a + b[Candidates],
    a ~ dnorm(0, 10),
    b[Candidates] ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = semFrame, iter = 10000, chains = 4, cores = 4
)
```
  
```{r}
precis(m0_bayes_real)
precis(m1_bayes_real)
```

#### Comparison individual/organisation pair
Compare sentiments of individual pairs and provide a brief interpretation (e.g. CIs) 

```{r}
# include your code and output in the document
# compare donald trump and hillary clinton
```

## Question 2 - Website visits (between groups - Two factors)

### Loading the data
Our ages added up to 65 (23, 22, 21) and 66 % 3 = 0. This means that we had to use the websitevisit2 data set.
  
```{r}
# setwd("/Users/suhaibbasir/Documents/CS/MSc/SRDS/SeminarDataScience/Assignment_1")
websitevisits <- read.csv("webvisit0.csv", header = TRUE, sep = ",")
head(websitevisits)
```


### Conceptual model
Make a conceptual model underlying this research question: Does the version of the website, the portal, or a combination of the two had an impact on the number of pages visited.

Based on the conceptual model on the research question our conceptual model consists of the following factors:
- Independent variables: Portal (2 levels), Version (2 levels)
- Dependent variable: Number of pages visited

This is visualised in the diagram below:
```{r}
knitr::include_graphics("conceptualModel2.png")
```


### Specific Mathematical model
Describe the mathematical model that you fit on the data. Take for this the complete model that you fit on the data. Also, explain your selection for the priors. Assume Gaussian distribution for the number of page visits.

The mathematical model that we fit on the data is a linear model. The model is described by the following formula:

$$
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1}x_{i2} + \epsilon_i
$$
  
Where $y_i$ is the number of pages visited by participant $i$, $x_{i1}$ is the portal used by participant $i$, 
$x_{i2}$ is the version of the website used by participant $i$ and $\epsilon_i$ is the error term for participant $i$. 
The $\beta$'s are the coefficients of the model. $\beta_0$ is the intercept, $\beta_1$ is the effect of the portal, 
$\beta_2$ is the effect of the version and $\beta_3$ is the interaction effect between the portal and the version.

### Create Synthetic data
Create a synthetic data set with a clear interaction effect between the two factors for verifying your analysis later on. Report the values of the coefficients of the linear model used to generate synthetic data.

```{r}
# include your code for generating the synthetic data
# Set a seed for reproducibility
set.seed(123)
n_samples <- 100
X <- 1:n_samples
version <- sample(c(0, 1), n_samples, replace = TRUE)
portal <- sample(c(0, 1), n_samples, replace = TRUE)
pages <- round(rnorm(n_samples, mean = 10 + 2 * version + 3 * portal + 4 * version * portal, sd = 1))
synthetic_data <- data.frame(X, pages, version, portal)
head(synthetic_data)
```
10, 2, 3, and 4 were the coefficients used for $\beta_0 , \beta_1 , \beta_2 , \beta_3$ respectively.


### Visual inspection
Graphically examine the mean page visits for the four different conditions. Give a short explanation of the figure.


```{r}
# include your code and output in the document
library(ggplot2)

mean_pages <- aggregate(pages ~ version + portal, websitevisits, mean)
mean_pages$version <- factor(mean_pages$version, labels = c("Version 0", "Version 1"))
mean_pages$portal <- factor(mean_pages$portal, labels = c("Portal 0", "Portal 1"))

# Generate plot
ggplot(mean_pages, aes(x = interaction(version, portal, sep = "-"), y = pages)) +
  geom_bar(stat = "identity") +
  labs(x = "Condition (Version-Portal)", y = "Mean page visits") +
  theme_minimal()
```
When the portal and version are 1, we get the most page visits. When the portal is 0 and the version is 1, we get the least page visits.

### Frequentist Approach

#### Model verification
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of AICc, F-value, p-value etc.

```{r}
# include your analysis code of synthetic data and output in the document
m0 <- lm(pages ~ 1, data = synthetic_data)
m1 <- lm(pages ~ version, data = synthetic_data)
m2 <- lm(pages ~ portal, data = synthetic_data)
m3 <- lm(pages ~ version + portal, data = synthetic_data)
m4 <- lm(pages ~ version * portal, data = synthetic_data)

# Compare models
anova(m0, m1, m2, m3, m4, test = "Chisq")
summary(m4)
AIC(m0, m1, m2, m3, m4)
```
The intercept and the coefficients for version, portal, and version:portal are very close to the values used to generate the synthetic data (10, 2.05, 3.16, and 3.22, respectively 10, 2, 3, 4 before), and all coefficients are highly significant (p < 2e-16). This confirms that the model has successfully identified and estimated the underlying relationships in the synthetic data.
The model with the best fit is m4 as the AIC was the lowest for m4, which is the model that includes the interaction effect.
The Multiple R-squared value is 0.9103, indicating that the model explains approximately 91% of the variability in page visits.
The F-statistic is 324.7 (with a highly significant p-value), indicating that the variation explained by our model is significantly greater than the unexplained variation. This further underscores the strength and validity of our model.

#### Model analysis with Gaussian distribution assumed
Redo the analysis now on the real data set. Assume Gaussian distribution for the number of page visits. Provide a short interpretation of the results, with an interpretation of AICc, F-value, p-value, etc.
```{r}
# include your code and output in the document
m0 <- lm(pages ~ 1, data = websitevisits)
m1 <- lm(pages ~ version, data = websitevisits)
m2 <- lm(pages ~ portal, data = websitevisits)
m3 <- lm(pages ~ version + portal, data = websitevisits)
m4 <- lm(pages ~ version * portal, data = websitevisits)

# Compare models
anova(m0, m1, m2, m3, m4, test = "Chisq")
summary(m4)
# Compare AIC
AIC(m0, m1, m2, m3, m4)
```
The intercept and the coefficients for version, portal, and version:portal are 19.6280, -7.6239, 13.4663, and 29.8808, respectively, and all coefficients are highly significant (p < 2e-16). This suggests that the linear model has successfully captured the underlying relationships between version, portal, and the interaction term, and the number of page visits.
The model with the best fit is m4 as the AIC was the lowest for m4, which is the model that includes the interaction effect. 
The Multiple R-squared value is 0.9036, indicating that the model explains approximately 90% of the variability in page visits.
The F-statistic is 3110 (with a highly significant p-value), indicating that the variation explained by our model is significantly greater than the unexplained variation.

#### Assumption analysis
Redo the analysis on the real website visit data set.  This time assume a Poisson distribution for the number of page visits. For the best fitting models (Gaussian and Poisson), examine graphically the distribution of the residuals for the model that assumes Gaussian distribution and the model that assumes Poisson distribution. Give a brief interpretation of Poisson and Gaussian distribution assumptions.

```{r}
# include your code and output in the document
# Gaussian distribution
m4 <- lm(pages ~ version * portal, data = websitevisits)
# Poisson distribution
m4_poisson <- glm(pages ~ version * portal, data = websitevisits, family = "poisson")

# # Compare models
summary(m4)
summary(m4_poisson)

# Plot residuals as QQ plots
par(mfrow = c(1, 2))
plot(m4, which = 1)
plot(m4_poisson, which = 1)

par(mfrow = c(1, 2))
qqnorm(residuals(m4))
qqline(residuals(m4))
qqnorm(residuals(m4_poisson))
qqline(residuals(m4_poisson))
```
The Q-Q plot for m4 where points deviate from the line in the tails suggests that the residuals are not normally distributed.
On the other hand, the Q-Q plot for m4_poisson where points follow the line suggests that the residuals are consistent with the Poisson distribution.

#### Simple effect analysis
Continue with the model that assumes a Poisson distribution. If the analysis shows a significant two-way interaction effect, conduct a Simple Effect analysis to explore this interaction effect in more detail. Provide a brief interpretation of the results.

```{r}
# include your code and output in the document
# Poisson distribution
summary(m4_poisson)

# Simple effect analysis
head(websitevisits$version)
head(websitevisits$portal)
websitevisits$simple <- interaction(websitevisits$version, websitevisits$portal)
levels(websitevisits$simple)

contrastSimple <- c(1, -1, 0, 0) # old consumers
contrastComplex <- c(0, 0, 1, -1) # new companies

SimpleEff <- cbind(contrastSimple, contrastComplex)
contrasts(websitevisits$simple) <- SimpleEff # now we link the two contrasts with the factor simple

simpleEffectModel <- lm(pages ~ simple, data = websitevisits)
summary(simpleEffectModel)
```
The linear model applied to the website visit data, with page visits as the dependent variable and the interaction between portal and version as independent variables, explained approximately 90.36% of the variation in page visits. 
Both the simple (version 0 portal 0 vs version 0 portal 1) and complex (version 1 portal 0 vs version 1 portal 1) contrast terms were statistically significant, indicating there are differences in page visits for these portal-version combinations. 
The model was statistically significant, affirming that both website version and portal type significantly impact the number of pages visited by users.

#### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.
In this study, we aimed to investigate the effect of website version and portal type on the number of pages visited by users. 
We found that the model that best fit the data was the model that included the interaction effect between version and portal. 
We plotted a Q-Q plot for both the Gaussian and Poisson distributions, and found that the residuals did not follow the line for the Gaussian distribution, but were consistent with the Poisson distribution.
We also conducted a simple effect analysis to explore the interaction effect in more detail. 
Our analysis revealed a significant effect for version 0 of the website on the number of pages visited, with users estimated to visit approximately 3.81 more pages compared to the baseline (t = 15.56, p < 2e-16).
In contrast, there was a significantly negative effect for version 1 of the website on page visits, with an estimate indicating that users visited approximately 11.13 fewer pages compared to the baseline (t = -45.96, p < 2e-16).
However, when considering the interaction effect of the version and portal, there was a significant positive effect, with an estimated 28.41 additional page visits for a one-unit increase in the interaction term (t = 82.48, p < 2e-16).

### Bayesian Approach
For the Bayesian analyses, use the rethinking and/or BayesianFirstAid library

#### Model description

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Assume Poisson distribution for the number of page visits. Justify the priors.

The mathematical model fitted on the most extensive model is as follows:

$$
\begin{aligned}
\text{pages} &\sim \text{Poisson}(\lambda) \\
\log(\lambda) &= \alpha + \beta_{\text{version}} \cdot \text{version} + \beta_{\text{portal}} \cdot \text{portal} + \beta_{\text{version_portal}} \cdot \text{version} \cdot \text{portal} \\
\alpha &\sim \text{Normal}(0, 10) \\
\beta_{\text{version}} &\sim \text{Normal}(0, 10) \\
\beta_{\text{portal}} &\sim \text{Normal}(0, 10) \\
\beta_{\text{version_portal}} &\sim \text{Normal}(0, 10) \\
\end{aligned}
$$

The priors are justified as follows:
- $\alpha$: The intercept is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because the intercept is assumed to be normally distributed around 0, with a standard deviation of 10.
- $\beta_{\text{version}}$: The version coefficient is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because the version coefficient is assumed to be normally distributed around 0, with a standard deviation of 10.
- $\beta_{\text{portal}}$: The portal coefficient is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because the portal coefficient is assumed to be normally distributed around 0, with a standard deviation of 10.
- $\beta_{\text{version_portal}}$: The interaction coefficient is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because the interaction coefficient is assumed to be normally distributed around 0, with a standard deviation of 10.


####  Verification Analysis
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of WAIC, and 95% credibility interval of coefficients for individual celebrities.

```{r, warning=FALSE, message=FALSE, results='hide'}
# include your analysis code of synthetic data and output in the document
library(rethinking)
synthetic_data$portalF <- as.factor(synthetic_data$portal)
synthetic_data$versionF <- as.factor(synthetic_data$version)
m_synthetic0 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept,
    intercept ~ dnorm(10, 10)),
  data = synthetic_data, iter = 10000, chains = 4, cores = 4
)

m_synthetic1 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_version * version,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_version ~ dnorm(2, 10) # Prior for version coefficient
  ),
  data = synthetic_data, iter = 10000, chains = 4, cores = 4
)

m_synthetic2 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_portal * portal + beta_interaction * version * portal,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_portal ~ dnorm(3, 10), # Prior for portal coefficient
    beta_interaction ~ dnorm(4, 10) # Prior for interaction coefficient
  ),
  data = synthetic_data, iter = 10000, chains = 4, cores = 4
)

m_synthetic3 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_version * version + beta_portal * portal + beta_interaction * version * portal,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_version ~ dnorm(2, 10), # Prior for version coefficient
    beta_portal ~ dnorm(3, 10), # Prior for portal coefficient
    beta_interaction ~ dnorm(4, 10) # Prior for interaction coefficient
  ),
  data = synthetic_data, iter = 10000, chains = 4, cores = 4
)
```
```{r}
precis(m_synthetic0, depth = 1, prob = 0.95)
precis(m_synthetic1, depth = 1, prob = 0.95)
precis(m_synthetic2, depth = 1, prob = 0.95)
precis(m_synthetic3, depth = 1, prob = 0.95)
compare(m_synthetic0, m_synthetic1, m_synthetic2, m_synthetic3)
```
Comparing the models with synthetic data using WAIC, m_synthetic1 is the best model, with a WAIC of 1363.6. This models the effect of the version. The other models have slightly higher WAIC values, suggesting that they are not as good at predicting the data. 

In the **`m_synthetic1`** model, the "beta_version" variable has a 95% credibility interval of [0.08, 0.21], meaning we can be 95% confident that the true value of **`beta_version`** lies within this range. Because this interval does not include zero, it is statistically significant.


#### Model comparison

Redo the analysis on actual data. Assume Poisson distribution for the number of page visits. Provide brief interpretation of the analysis results (e.g. WAIC, and 95% credibility interval of coefficients).

```{r, warning=FALSE, message=FALSE, results='hide'}
# include your code and output in the document
library(rethinking)
m_actual0 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept,
    intercept ~ dnorm(10, 10)),
  data = websitevisits, iter = 10000, chains = 4, cores = 4
)

m_actual1 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_version * version,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_version ~ dnorm(2, 10) # Prior for version coefficient
  ),
  data = websitevisits, iter = 10000, chains = 4, cores = 4
)

m_actual2 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_portal * portal + beta_interaction * version * portal,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_portal ~ dnorm(3, 10), # Prior for portal coefficient
    beta_interaction ~ dnorm(4, 10) # Prior for interaction coefficient
  ),
  data = websitevisits, iter = 10000, chains = 4, cores = 4
)

m_actual3 <- map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- intercept + beta_version * version + beta_portal * portal + beta_interaction * version * portal,
    intercept ~ dnorm(10, 10), # Prior for intercept
    beta_version ~ dnorm(2, 10), # Prior for version coefficient
    beta_portal ~ dnorm(3, 10), # Prior for portal coefficient
    beta_interaction ~ dnorm(4, 10) # Prior for interaction coefficient
  ),
  data = websitevisits, iter = 10000, chains = 4, cores = 4
)
```
```{r}
precis(m_actual0, depth = 1, prob = 0.95)
precis(m_actual1, depth = 1, prob = 0.95)
precis(m_actual2, depth = 1, prob = 0.95)
precis(m_actual3, depth = 1, prob = 0.95)
compare(m_actual0, m_actual1, m_actual2, m_actual3)
```
Comparing the models using WAIC, m_actual3 is the best model, with a WAIC of 6057.3. This models the interaction effect. The other models have significantly higher WAIC values, suggesting that they are not as good at predicting the data. 

In the **`m_actual3`** model, all coefficients are statistically significant, with the "version" variable decreasing the log count of pages, the "portal" variable increasing it, and their interaction significantly modifying the outcome as well.


# Part 3 - Multilevel model

## Loading the data
Our combined student numbers are: 5059151+5096790+4658272 = 14824213 % 3 = 0. Therefore we will use the file set0.csv

```{r}
# load set0.csv
set0 <- read.csv("set0.csv")
```

## Visual inspection
Use graphics to inspect the distribution of the score, and relationship between session and score. Give a short description of the figure.


```{r}
# include your code and output in the document

# # plot the distribution of the score
# hist(set0$score)

# # plot the relationship between session and score
# plot(set0$session, set0$score)

library(ggplot2)
ggplot(set0, aes(x = score)) + 
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  theme_minimal() +
  labs(title = "Distribution of Scores",
       x = "Score", 
       y = "Frequency")

ggplot(set0, aes(x = session, y = score)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  theme_minimal() +
  labs(title = "Relationship between Session and Score",
       x = "Session", 
       y = "Score")

```

The visual presents a bell-shaped curve, characteristic of a normal distribution. The scores range from 3 to 34, with a central tendency represented by the median value of 19. The distribution is symmetrically centered around the median, indicating a balanced dataset.

The relationship between session and scores shows a linear function between the session number and the score. The higher the session number, the higher the score.

## Frequentist approach

### Multilevel analysis
Conduct multilevel analysis and calculate 95% confidence intervals thereby assuming a Gaussian distribution for the scores, determine:

* If session has an impact on people score
* If there is significant variance between the participants in their score


```{r}
# include your code and output in the document
library(nlme)
m1 <- lme(score ~ session, random = ~ 1 | subject, data = set0, method = "ML")
summary(m1)
conf_int <- intervals(m1, level = 0.95)
conf_int
```


### Report section for a scientific publication
A linear mixed-effects model analysis was conducted to examine the relationship between the predictor variable, session, and the response variable, score.

The session predictor variable showed significant effects on the response variable with an estimated value of 1.00562 (SE = 0.0157501, t = 63.84847, p < 0.001). These results indicated that the session variable had a significant impact on the scores.

Furthermore, the random effects component indicated that the intercepts for subjects exhibited a standard deviation of 4.836719, suggesting variations in the baseline values of the response variable among individuals. This suggests that individuals had distinct starting points for their scores, independent of the session variable.

A linear mixed-effects model analysis was conducted to examine the relationship between the predictor variable, session, and the response variable, score.

The session predictor variable showed significant effects on the response variable with an estimated value of 1.00562 (SE = 0.0157501, t = 63.84847, p < 0.001). These results indicated that the session variable had a significant impact on the scores.

Furthermore, the random effects component indicated that the intercepts for subjects exhibited a standard deviation of 4.836719, suggesting variations in the baseline values of the response variable among individuals. This suggests that individuals had distinct starting points for their scores, independent of the session variable.


## Bayesian approach
For the Bayesian analyses, use the rethinking and/or BayesianFirstAid library

### Model description

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown).  Assume a Gaussian distribution for the scores. Justify the priors.

The mathematical model that is fitted on the most extensive model is as follows:

$$
\begin{aligned}
\text{score} &\sim \text{Normal}(\mu, \sigma) \\
\mu &= \alpha + \beta_{\text{session}} \cdot \text{session} + \beta_{\text{subject}} \cdot \text{subject} + \beta_{\text{session, subject}} \cdot \text{session} \cdot \text{subject} \\
\alpha &\sim \text{Normal}(0, 10) \\
\beta_{\text{session}} &\sim \text{Normal}(0, 10) \\
\sigma &\sim \text{Exponential}(1) \\
\end{aligned}
$$

The priors are justified as follows:

* $\alpha$: The intercept is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because we do not have any prior knowledge about the intercept and we assume that the intercept is normally distributed.
* $\beta_{\text{session}}$: The slope is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because we do not have any prior knowledge about the slope and we assume that the slope is normally distributed.
* $\beta_{\text{subject}}$: The slope is assumed to be normally distributed with a mean of 0 and a standard deviation of 10. This is because we do not have any prior knowledge about the slope and we assume that the slope is normally distributed.
* $\sigma$: The standard deviation is assumed to be exponentially distributed with a rate of 1. This is because we do not have any prior knowledge about the standard deviation and we assume that the standard deviation is exponentially distributed.

### Model comparison

Compare models with with increasing complexity. 

```{r, warning=FALSE, message=FALSE, results='hide'}
# include your code and output in the document
library(rethinking)
m0_set0 <- map2stan( 
  alist(
    score ~ dnorm(mu, sigma),
    mu <- a,
    # fixed priors
    a ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = set0, iter = 10000, chains = 4, cores = 4,
  log_lik = TRUE, control = list(adapt_delta = 0.99)
)
precis(m0_set0, depth = 1, prob = 0.95)

m1_set0 <- map2stan(
  alist(
    score ~ dnorm(mu, sigma),
    mu <- a + a[subject],
    # adaptive priors
    a[subject] ~ dnorm(0, sigma_subject),
    # hyperpriors
    sigma_subject ~ dnorm(0, 10),
    # fixed priors
    a ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = set0, iter = 10000, chains = 4, cores = 4,
  log_lik = TRUE, control = list(adapt_delta = 0.99)
)
precis(m1_set0, depth = 1, prob = 0.95)

m2_set0 <- map2stan(
  alist(
    score ~ dnorm(mu, sigma),
    mu <- a + a[subject] + b_session * session ,
    # adaptive priors
    a[subject] ~ dnorm(0, sigma_subject),
    # hyperpriors
    sigma_subject ~ dnorm(0, 10),
    # fixed priors
    a ~ dnorm(0, 10),
    b_session ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = set0, iter = 10000, chains = 4, cores = 4,
  log_lik = TRUE, control = list(adapt_delta = 0.99)
)
precis(m2_set0, depth = 1, prob = 0.95)
```

```{r}
compare(m0_set0, m1_set0, m2_set0)
```
Based on the Watanabe-Akaike Information Criterion (WAIC), which is used to compare model fit, model m2_set0, with a WAIC score of 869.2 and a weight of 1, provides the best fit to the data. 
This model incorporates both subject-specific variability and the fixed effect of sessions. Conversely, the models m1_set0 and m0_set0, excluding the session effect and both subject and session effects respectively, perform significantly worse.
These findings show the importance of subject and session when interpreting the scores data. 

### Estimates examination

Examine the estimate of parameters of the model with best fit, and provide a brief interpretation.

```{r}
# include your code and output in the document
precis(m2_set0, depth = 1, prob = 0.95)
```

These results suggest that both the subject and session have a significant impact on the score. 
There is considerable variation in score across different subjects, and there is also a significant increase in score with each increase in session. 
The model fits the data reasonably well, but there is still some unexplained variation in score, as indicated by the value of sigma.
